{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Step 1: Preprocessing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this step\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import unicodedata\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the json file and save the data line by line in a list\n",
    "data = []\n",
    "with open(\"controversial-comments.jsonl\", 'r') as f:\n",
    "    for line in f:\n",
    "       data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Well it's great that he did something about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You are right Mr. President.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>You have given no input apart from saying I am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I get the frustration but the reason they want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I am far from an expert on TPP and I would ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   con                                                txt\n",
       "0    0  Well it's great that he did something about th...\n",
       "1    0                       You are right Mr. President.\n",
       "2    0  You have given no input apart from saying I am...\n",
       "3    0  I get the frustration but the reason they want...\n",
       "4    0  I am far from an expert on TPP and I would ten..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the list into a dataframe \n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>well it's great that he did something about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>you are right mr. president.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>you have given no input apart from saying i am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>i get the frustration but the reason they want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i am far from an expert on tpp and i would ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   con                                                txt\n",
       "0    0  well it's great that he did something about th...\n",
       "1    0                       you are right mr. president.\n",
       "2    0  you have given no input apart from saying i am...\n",
       "3    0  i get the frustration but the reason they want...\n",
       "4    0  i am far from an expert on tpp and i would ten..."
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert all text to lowercase\n",
    "df['txt'] = df['txt'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of punctuation characters\n",
    "punctuation = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                            if unicodedata.category(chr(i)).startswith('P'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>well its great that he did something about tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>you are right mr president</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>you have given no input apart from saying i am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>i get the frustration but the reason they want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i am far from an expert on tpp and i would ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   con                                                txt\n",
       "0    0  well its great that he did something about tho...\n",
       "1    0                         you are right mr president\n",
       "2    0  you have given no input apart from saying i am...\n",
       "3    0  i get the frustration but the reason they want...\n",
       "4    0  i am far from an expert on tpp and i would ten..."
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the punctuation dictionary to remove all punctuation from text column\n",
    "df['txt'] = [string.translate(punctuation) for string in df['txt']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\myraw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Due to an error I received when trying to tokenize words I had to download punkt\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "      <th>txt_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>well its great that he did something about tho...</td>\n",
       "      <td>[well, its, great, that, he, did, something, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>you are right mr president</td>\n",
       "      <td>[you, are, right, mr, president]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>you have given no input apart from saying i am...</td>\n",
       "      <td>[you, have, given, no, input, apart, from, say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>i get the frustration but the reason they want...</td>\n",
       "      <td>[i, get, the, frustration, but, the, reason, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i am far from an expert on tpp and i would ten...</td>\n",
       "      <td>[i, am, far, from, an, expert, on, tpp, and, i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   con                                                txt  \\\n",
       "0    0  well its great that he did something about tho...   \n",
       "1    0                         you are right mr president   \n",
       "2    0  you have given no input apart from saying i am...   \n",
       "3    0  i get the frustration but the reason they want...   \n",
       "4    0  i am far from an expert on tpp and i would ten...   \n",
       "\n",
       "                                       txt_tokenized  \n",
       "0  [well, its, great, that, he, did, something, a...  \n",
       "1                   [you, are, right, mr, president]  \n",
       "2  [you, have, given, no, input, apart, from, say...  \n",
       "3  [i, get, the, frustration, but, the, reason, t...  \n",
       "4  [i, am, far, from, an, expert, on, tpp, and, i...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To prepare for removing stopwords, I have to first tokenize the data\n",
    "df['txt_tokenized'] = df['txt'].apply(word_tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\myraw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now I have to download the set of stopwords since it is my first time using it\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "      <th>txt_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>well its great that he did something about tho...</td>\n",
       "      <td>[well, great, something, beliefs, office, doub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>you are right mr president</td>\n",
       "      <td>[right, mr, president]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>you have given no input apart from saying i am...</td>\n",
       "      <td>[given, input, apart, saying, wrong, argument,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>i get the frustration but the reason they want...</td>\n",
       "      <td>[get, frustration, reason, want, way, foundati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i am far from an expert on tpp and i would ten...</td>\n",
       "      <td>[far, expert, tpp, would, tend, agree, lot, pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   con                                                txt  \\\n",
       "0    0  well its great that he did something about tho...   \n",
       "1    0                         you are right mr president   \n",
       "2    0  you have given no input apart from saying i am...   \n",
       "3    0  i get the frustration but the reason they want...   \n",
       "4    0  i am far from an expert on tpp and i would ten...   \n",
       "\n",
       "                                       txt_tokenized  \n",
       "0  [well, great, something, beliefs, office, doub...  \n",
       "1                             [right, mr, president]  \n",
       "2  [given, input, apart, saying, wrong, argument,...  \n",
       "3  [get, frustration, reason, want, way, foundati...  \n",
       "4  [far, expert, tpp, would, tend, agree, lot, pr...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stop words\n",
    "df['txt_tokenized'] = df['txt_tokenized'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To apply NLTK’s PorterStemmer, I must first create a stemmer\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "      <th>txt_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>well its great that he did something about tho...</td>\n",
       "      <td>[well, great, someth, belief, offic, doubt, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>you are right mr president</td>\n",
       "      <td>[right, mr, presid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>you have given no input apart from saying i am...</td>\n",
       "      <td>[given, input, apart, say, wrong, argument, cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>i get the frustration but the reason they want...</td>\n",
       "      <td>[get, frustrat, reason, want, way, foundat, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i am far from an expert on tpp and i would ten...</td>\n",
       "      <td>[far, expert, tpp, would, tend, agre, lot, pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   con                                                txt  \\\n",
       "0    0  well its great that he did something about tho...   \n",
       "1    0                         you are right mr president   \n",
       "2    0  you have given no input apart from saying i am...   \n",
       "3    0  i get the frustration but the reason they want...   \n",
       "4    0  i am far from an expert on tpp and i would ten...   \n",
       "\n",
       "                                       txt_tokenized  \n",
       "0  [well, great, someth, belief, offic, doubt, tr...  \n",
       "1                                [right, mr, presid]  \n",
       "2  [given, input, apart, say, wrong, argument, cl...  \n",
       "3  [get, frustrat, reason, want, way, foundat, co...  \n",
       "4  [far, expert, tpp, would, tend, agre, lot, pro...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the stemmer to the tokenized text\n",
    "df['txt_tokenized'] = df['txt_tokenized'].apply(lambda x: [porter.stem(word) for word in x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed dataframe to a csv file for easy recall\n",
    "df.to_csv('wk2_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Step 2A: Word Count Vector***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this step\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "      <th>txt_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>well its great that he did something about tho...</td>\n",
       "      <td>['well', 'great', 'someth', 'belief', 'offic',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>you are right mr president</td>\n",
       "      <td>['right', 'mr', 'presid']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>you have given no input apart from saying i am...</td>\n",
       "      <td>['given', 'input', 'apart', 'say', 'wrong', 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>i get the frustration but the reason they want...</td>\n",
       "      <td>['get', 'frustrat', 'reason', 'want', 'way', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>i am far from an expert on tpp and i would ten...</td>\n",
       "      <td>['far', 'expert', 'tpp', 'would', 'tend', 'agr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  con                                                txt  \\\n",
       "0           0    0  well its great that he did something about tho...   \n",
       "1           1    0                         you are right mr president   \n",
       "2           2    0  you have given no input apart from saying i am...   \n",
       "3           3    0  i get the frustration but the reason they want...   \n",
       "4           4    0  i am far from an expert on tpp and i would ten...   \n",
       "\n",
       "                                       txt_tokenized  \n",
       "0  ['well', 'great', 'someth', 'belief', 'offic',...  \n",
       "1                          ['right', 'mr', 'presid']  \n",
       "2  ['given', 'input', 'apart', 'say', 'wrong', 'a...  \n",
       "3  ['get', 'frustrat', 'reason', 'want', 'way', '...  \n",
       "4  ['far', 'expert', 'tpp', 'would', 'tend', 'agr...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load up preprocessed data\n",
    "test = pd.read_csv('wk2_clean.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create count vectorizer function\n",
    "count = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the tokenized text column into a string\n",
    "test['txt_tokenized'] = test['txt_tokenized'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a sample of rows\n",
    "test_df = test.sample(frac = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<190000x74709 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3079001 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call wordCount function on the tokenized text\n",
    "bag_of_words = count.fit_transform(test_df['txt_tokenized'])\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0],\n",
       "       [1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below is from a previous run through were I only sampled 5 rows, so I could make sure everything worked correctly\n",
    "# by displaying the dense matrix before processing a larger number of sample rows. \n",
    "arr = bag_of_words.toarray()\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allow</th>\n",
       "      <th>candid</th>\n",
       "      <th>citizen</th>\n",
       "      <th>countri</th>\n",
       "      <th>dumb</th>\n",
       "      <th>go</th>\n",
       "      <th>last</th>\n",
       "      <th>legal</th>\n",
       "      <th>link</th>\n",
       "      <th>millennia</th>\n",
       "      <th>...</th>\n",
       "      <th>remov</th>\n",
       "      <th>republican</th>\n",
       "      <th>say</th>\n",
       "      <th>someth</th>\n",
       "      <th>these</th>\n",
       "      <th>trump</th>\n",
       "      <th>two</th>\n",
       "      <th>want</th>\n",
       "      <th>whole</th>\n",
       "      <th>wors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   allow  candid  citizen  countri  dumb  go  last  legal  link  millennia  \\\n",
       "0      0       1        0        0     0   0     0      0     0          0   \n",
       "1      0       0        0        0     0   0     0      0     0          0   \n",
       "2      0       0        1        0     0   1     0      1     1          0   \n",
       "3      1       1        0        1     1   0     1      0     0          0   \n",
       "4      0       0        0        0     0   0     0      0     0          1   \n",
       "\n",
       "   ...  remov  republican  say  someth  these  trump  two  want  whole  wors  \n",
       "0  ...      0           1    0       0      0      0    0     0      0     1  \n",
       "1  ...      1           0    0       0      0      0    0     0      0     0  \n",
       "2  ...      0           0    1       1      0      1    0     1      0     0  \n",
       "3  ...      0           0    0       0      1      0    1     0      1     0  \n",
       "4  ...      0           0    0       0      0      0    0     0      0     0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also from the 5 row sample: Change into a pandas dataframe to view the pretty version with the column names\n",
    "pd.DataFrame(arr, columns=count.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Step 2B: Part of Speech Tag Vector***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this step\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import pos_tag, pos_tag_sents\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\myraw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "      <th>txt_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>well its great that he did something about tho...</td>\n",
       "      <td>['well', 'great', 'someth', 'belief', 'offic',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>you are right mr president</td>\n",
       "      <td>['right', 'mr', 'presid']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>you have given no input apart from saying i am...</td>\n",
       "      <td>['given', 'input', 'apart', 'say', 'wrong', 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>i get the frustration but the reason they want...</td>\n",
       "      <td>['get', 'frustrat', 'reason', 'want', 'way', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>i am far from an expert on tpp and i would ten...</td>\n",
       "      <td>['far', 'expert', 'tpp', 'would', 'tend', 'agr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  con                                                txt  \\\n",
       "0           0    0  well its great that he did something about tho...   \n",
       "1           1    0                         you are right mr president   \n",
       "2           2    0  you have given no input apart from saying i am...   \n",
       "3           3    0  i get the frustration but the reason they want...   \n",
       "4           4    0  i am far from an expert on tpp and i would ten...   \n",
       "\n",
       "                                       txt_tokenized  \n",
       "0  ['well', 'great', 'someth', 'belief', 'offic',...  \n",
       "1                          ['right', 'mr', 'presid']  \n",
       "2  ['given', 'input', 'apart', 'say', 'wrong', 'a...  \n",
       "3  ['get', 'frustrat', 'reason', 'want', 'way', '...  \n",
       "4  ['far', 'expert', 'tpp', 'would', 'tend', 'agr...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load up preprocessed data\n",
    "test = pd.read_csv('wk2_clean.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a sample of rows\n",
    "test_df = test.sample(frac = 0.000005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"['hit', 'nail', 'head', 'girlfriend', 'tell', 'dad', 'trump', 'support', 'peopl', 'give', 'cabinet', 'posit', 'totransit', 'team', 'posit', 'big', 'swamp', 'list', 'essenti', 'told', 'bias', 'news', 'cant', 'argu', 'anyth', 'someon', 'doesnt', 'like', 'untrustworthi', 'never', 'mind', 'opinion', 'even', 'given', 'list', 'peopl', 'appoint', 'jobscredentialsexperi']\",\n",
       "  'JJ'),\n",
       " (\"['cnn', 'say', 'air', 'right', 'thousand', 'email', 'word', 'thousand', 'email']\",\n",
       "  'NNP'),\n",
       " (\"['exactli']\", 'NNP'),\n",
       " (\"['see', 'comment', 'httpwwwredditcomrpoliticscomments5bxqrpdistrictvotersoverwhelminglyapprovereferendumd9sk707', 'thorough', 'argument', 'care', 'simpli', 'put', 'character', 'issu', 'wrong', 'dc', 'resid', 'arent', 'demand', 'vote', 'power', 'demand', 'recognit', 'right', 'note', 'power', 'pay', 'feder', 'tax', 'like', 'everi', 'american', 'dont', 'get', 'vote', 'power', 'congress', 'represent', 'senat', 'didnt', 'get', 'vote', 'presid', 'sixti', 'arent', 'even', 'grant', 'right', 'govern', 'citi', 'congress', 'grant', 'us', 'nomin', 'author', 'self', 'govern', 'retain', 'suprem', 'author', 'us', 'often', 'strike', 'law', 'write', 'law', 'us', 'without', 'input', 'consent']\",\n",
       "  'NNP'),\n",
       " (\"['everi', 'squirrel', 'find', 'nut', 'sometim', 'saw', 'articl', 'former', 'lawyer', 'houston', 'area', 'wrote', 'breitbart', 'inform', 'object', 'littl', 'bia', 'articl', 'like', 'sourc', 'except', 'rule', 'writer', 'would', 'better', 'serv', 'tri', 'find', 'anoth', 'publish', 'honesti']\",\n",
       "  'NN')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use pretrained parts of speech tagger\n",
    "text_tagged = pos_tag(test_df['txt_tokenized'])\n",
    "text_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure why that didn't tag each word in the row, so I'm going to try this tip from a classmate.\n",
    "# Create function for the tagger\n",
    "def tokenizer(arr):\n",
    "    tokens = [pos_tag(word_tokenize(str(i))) for i in arr.split()]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list\n",
    "tagged_text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a for loop to tag each word by row\n",
    "for row in test_df.iterrows():\n",
    "    tags = test_df['txt_tokenized'].apply(tokenizer)\n",
    "    tagged_text.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56775     [[([, NN), ('hit, ''), (', ''), (,, ,)], [('na...\n",
       " 713370    [[([, JJ), ('cnn, NNP), (', POS), (,, ,)], [('...\n",
       " 671952      [[([, JJ), ('exactli, NNP), (', POS), (], NN)]]\n",
       " 294102    [[([, JJ), ('see, NNP), (', POS), (,, ,)], [('...\n",
       " 947269    [[([, JJ), ('everi, NNP), (', POS), (,, ,)], [...\n",
       " Name: txt_tokenized, dtype: object,\n",
       " 56775     [[([, NN), ('hit, ''), (', ''), (,, ,)], [('na...\n",
       " 713370    [[([, JJ), ('cnn, NNP), (', POS), (,, ,)], [('...\n",
       " 671952      [[([, JJ), ('exactli, NNP), (', POS), (], NN)]]\n",
       " 294102    [[([, JJ), ('see, NNP), (', POS), (,, ,)], [('...\n",
       " 947269    [[([, JJ), ('everi, NNP), (', POS), (,, ,)], [...\n",
       " Name: txt_tokenized, dtype: object,\n",
       " 56775     [[([, NN), ('hit, ''), (', ''), (,, ,)], [('na...\n",
       " 713370    [[([, JJ), ('cnn, NNP), (', POS), (,, ,)], [('...\n",
       " 671952      [[([, JJ), ('exactli, NNP), (', POS), (], NN)]]\n",
       " 294102    [[([, JJ), ('see, NNP), (', POS), (,, ,)], [('...\n",
       " 947269    [[([, JJ), ('everi, NNP), (', POS), (,, ,)], [...\n",
       " Name: txt_tokenized, dtype: object,\n",
       " 56775     [[([, NN), ('hit, ''), (', ''), (,, ,)], [('na...\n",
       " 713370    [[([, JJ), ('cnn, NNP), (', POS), (,, ,)], [('...\n",
       " 671952      [[([, JJ), ('exactli, NNP), (', POS), (], NN)]]\n",
       " 294102    [[([, JJ), ('see, NNP), (', POS), (,, ,)], [('...\n",
       " 947269    [[([, JJ), ('everi, NNP), (', POS), (,, ,)], [...\n",
       " Name: txt_tokenized, dtype: object,\n",
       " 56775     [[([, NN), ('hit, ''), (', ''), (,, ,)], [('na...\n",
       " 713370    [[([, JJ), ('cnn, NNP), (', POS), (,, ,)], [('...\n",
       " 671952      [[([, JJ), ('exactli, NNP), (', POS), (], NN)]]\n",
       " 294102    [[([, JJ), ('see, NNP), (', POS), (,, ,)], [('...\n",
       " 947269    [[([, JJ), ('everi, NNP), (', POS), (,, ,)], [...\n",
       " Name: txt_tokenized, dtype: object]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56775     [[([, NN)], [(', '')], [(h, NN)], [(i, NN)], [...\n",
       "713370    [[([, NN)], [(', '')], [(c, NNS)], [(n, NN)], ...\n",
       "671952    [[([, NN)], [(', '')], [(e, NN)], [(x, NN)], [...\n",
       "294102    [[([, NN)], [(', '')], [(s, NN)], [(e, NN)], [...\n",
       "947269    [[([, NN)], [(', '')], [(e, NN)], [(v, NN)], [...\n",
       "Name: txt_tokenized, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I don't know why that assigns so many empty spaces and why it repeats five times. \n",
    "# I tried a different method, but that ended up breaking it out by letter.\n",
    "x = test_df['txt_tokenized'].apply(lambda x: [pos_tag(word) for word in x])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's another way i tried that also broke it down to letters\n",
    "test_df['POS'] = [pos_tag(sent) for sent in test_df['txt_tokenized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "      <th>txt_tokenized</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>549694</th>\n",
       "      <td>549694</td>\n",
       "      <td>0</td>\n",
       "      <td>this would absolutely not shock me</td>\n",
       "      <td>['would', 'absolut', 'shock']</td>\n",
       "      <td>[([, NN), (', ''), (w, JJ), (o, IN), (u, JJ), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165376</th>\n",
       "      <td>165376</td>\n",
       "      <td>0</td>\n",
       "      <td>because i got in an argument with you months a...</td>\n",
       "      <td>['got', 'argument', 'month', 'ago', 'pretend',...</td>\n",
       "      <td>[([, NN), (', ''), (g, JJ), (o, IN), (t, NN), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338095</th>\n",
       "      <td>338095</td>\n",
       "      <td>0</td>\n",
       "      <td>politics by definition is the shift of power</td>\n",
       "      <td>['polit', 'definit', 'shift', 'power']</td>\n",
       "      <td>[([, NN), (', ''), (p, JJ), (o, IN), (l, NN), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51031</th>\n",
       "      <td>51031</td>\n",
       "      <td>0</td>\n",
       "      <td>didnt the left basically tell joe the plumber ...</td>\n",
       "      <td>['didnt', 'left', 'basic', 'tell', 'joe', 'plu...</td>\n",
       "      <td>[([, NN), (', ''), (d, NN), (i, NN), (d, VBP),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373650</th>\n",
       "      <td>373650</td>\n",
       "      <td>0</td>\n",
       "      <td>im not calling him a white supremacist merely ...</td>\n",
       "      <td>['im', 'call', 'white', 'supremacist', 'mere',...</td>\n",
       "      <td>[([, NN), (', ''), (i, JJ), (m, NN), (', ''), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  con                                                txt  \\\n",
       "549694      549694    0                 this would absolutely not shock me   \n",
       "165376      165376    0  because i got in an argument with you months a...   \n",
       "338095      338095    0       politics by definition is the shift of power   \n",
       "51031        51031    0  didnt the left basically tell joe the plumber ...   \n",
       "373650      373650    0  im not calling him a white supremacist merely ...   \n",
       "\n",
       "                                            txt_tokenized  \\\n",
       "549694                      ['would', 'absolut', 'shock']   \n",
       "165376  ['got', 'argument', 'month', 'ago', 'pretend',...   \n",
       "338095             ['polit', 'definit', 'shift', 'power']   \n",
       "51031   ['didnt', 'left', 'basic', 'tell', 'joe', 'plu...   \n",
       "373650  ['im', 'call', 'white', 'supremacist', 'mere',...   \n",
       "\n",
       "                                                      POS  \n",
       "549694  [([, NN), (', ''), (w, JJ), (o, IN), (u, JJ), ...  \n",
       "165376  [([, NN), (', ''), (g, JJ), (o, IN), (t, NN), ...  \n",
       "338095  [([, NN), (', ''), (p, JJ), (o, IN), (l, NN), ...  \n",
       "51031   [([, NN), (', ''), (d, NN), (i, NN), (d, VBP),...  \n",
       "373650  [([, NN), (', ''), (i, JJ), (m, NN), (', ''), ...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the new column\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('[', 'RB'),\n",
       "  (\"'like\", 'MD'),\n",
       "  (\"'\", \"''\"),\n",
       "  (',', ','),\n",
       "  (\"'bush\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'obama\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'war\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'wage\", 'NN'),\n",
       "  (\"'\", \"''\"),\n",
       "  (',', ','),\n",
       "  (\"'account\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'budget\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (']', 'NN')],\n",
       " [('[', 'RB'),\n",
       "  (\"'yike\", 'MD'),\n",
       "  (\"'\", \"''\"),\n",
       "  (',', ','),\n",
       "  (\"'that\", 'WP'),\n",
       "  (\"'\", \"''\"),\n",
       "  (',', ','),\n",
       "  (\"'question\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'im\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'afraid\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'your\", \"''\"),\n",
       "  (\"'\", \"''\"),\n",
       "  (',', ','),\n",
       "  (\"'beyond\", \"''\"),\n",
       "  (\"'\", \"''\"),\n",
       "  (',', ','),\n",
       "  (\"'help\", \"''\"),\n",
       "  (\"'\", 'POS'),\n",
       "  (']', 'NN')],\n",
       " [('[', 'NN'),\n",
       "  (\"'word\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'mean\", \"''\"),\n",
       "  (\"'\", \"''\"),\n",
       "  (',', ','),\n",
       "  (\"'staff\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'member\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'campaign\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'found\", 'IN'),\n",
       "  (\"'\", \"''\"),\n",
       "  (',', ','),\n",
       "  (\"'guilti\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'fraud\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'like\", 'IN'),\n",
       "  (\"'\", \"''\"),\n",
       "  (',', ','),\n",
       "  (\"'say\", 'VBP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (']', 'NN')],\n",
       " [('[', 'JJ'),\n",
       "  (\"'clearli\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'understand\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'system\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'that\", 'WP'),\n",
       "  (\"'\", \"''\"),\n",
       "  (',', ','),\n",
       "  (\"'exactli\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'work\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'httpsenwikipediaorgwikielectoralcollegeunitedstatesjointsessionofcongressandconting\",\n",
       "   'VBG'),\n",
       "  (\"'\", \"''\"),\n",
       "  (']', 'NN')],\n",
       " [('[', 'RB'),\n",
       "  (\"'good\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'point\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'let\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'dispel\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'fiction\", 'NN'),\n",
       "  (\"'\", \"''\"),\n",
       "  (',', ','),\n",
       "  (\"'republican\", 'JJ'),\n",
       "  (\"'\", \"''\"),\n",
       "  (',', ','),\n",
       "  (\"'dont\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'know\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'theyr\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'know\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'exactli\", 'NNP'),\n",
       "  (\"'\", 'POS'),\n",
       "  (',', ','),\n",
       "  (\"'theyr\", \"''\"),\n",
       "  (\"'\", 'POS'),\n",
       "  (']', 'NN')]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After 8 hours and 8,000 failed attempts at this, i read a post on stack overflow that said to use pos_tag_sents\n",
    "# and I liked how they solved their problem, so I copied their code and altered it to fit my assignment\n",
    "texts = test_df['txt_tokenized'].tolist()\n",
    "tagged_texts = pos_tag_sents(map(word_tokenize, texts))\n",
    "tagged_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('like', 'IN'),\n",
       "  ('bush', 'NN'),\n",
       "  ('did', 'VBD'),\n",
       "  ('to', 'TO'),\n",
       "  ('obama', 'VB'),\n",
       "  ('with', 'IN'),\n",
       "  ('wars', 'NNS'),\n",
       "  ('being', 'VBG'),\n",
       "  ('waged', 'VBD'),\n",
       "  ('that', 'WDT'),\n",
       "  ('were', 'VBD'),\n",
       "  ('not', 'RB'),\n",
       "  ('being', 'VBG'),\n",
       "  ('accounted', 'VBN'),\n",
       "  ('for', 'IN'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('budgets', 'NNS')],\n",
       " [('yikes', 'NNS'),\n",
       "  ('if', 'IN'),\n",
       "  ('thats', 'NNS'),\n",
       "  ('your', 'PRP$'),\n",
       "  ('question', 'NN'),\n",
       "  ('then', 'RB'),\n",
       "  ('im', 'VBZ'),\n",
       "  ('afraid', 'JJ'),\n",
       "  ('youre', 'NN'),\n",
       "  ('beyond', 'IN'),\n",
       "  ('help', 'NN')],\n",
       " [('they', 'PRP'),\n",
       "  ('do', 'VBP'),\n",
       "  ('and', 'CC'),\n",
       "  ('these', 'DT'),\n",
       "  ('words', 'NNS'),\n",
       "  ('mean', 'VBP'),\n",
       "  ('a', 'DT'),\n",
       "  ('staff', 'NN'),\n",
       "  ('member', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('campaign', 'NN'),\n",
       "  ('was', 'VBD'),\n",
       "  ('found', 'VBN'),\n",
       "  ('guilty', 'JJ'),\n",
       "  ('of', 'IN'),\n",
       "  ('fraud', 'NN'),\n",
       "  ('just', 'RB'),\n",
       "  ('like', 'IN'),\n",
       "  ('it', 'PRP'),\n",
       "  ('says', 'VBZ')],\n",
       " [('clearly', 'RB'),\n",
       "  ('you', 'PRP'),\n",
       "  ('are', 'VBP'),\n",
       "  ('not', 'RB'),\n",
       "  ('an', 'DT'),\n",
       "  ('understander', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('system', 'NN'),\n",
       "  ('thats', 'VBZ'),\n",
       "  ('exactly', 'RB'),\n",
       "  ('how', 'WRB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('works', 'VBZ'),\n",
       "  ('httpsenwikipediaorgwikielectoralcollegeunitedstatesjointsessionofcongressandcontingencies',\n",
       "   'NNS')],\n",
       " [('good', 'JJ'),\n",
       "  ('points', 'NNS'),\n",
       "  ('but', 'CC'),\n",
       "  ('lets', 'NNS'),\n",
       "  ('dispel', 'VBP'),\n",
       "  ('with', 'IN'),\n",
       "  ('this', 'DT'),\n",
       "  ('fiction', 'NN'),\n",
       "  ('that', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('republicans', 'NNPS'),\n",
       "  ('dont', 'NN'),\n",
       "  ('know', 'VBP'),\n",
       "  ('what', 'WP'),\n",
       "  ('theyre', 'VBP'),\n",
       "  ('doing', 'VBG'),\n",
       "  ('they', 'PRP'),\n",
       "  ('know', 'VBP'),\n",
       "  ('exactly', 'RB'),\n",
       "  ('what', 'WP'),\n",
       "  ('theyre', 'VBD'),\n",
       "  ('doing', 'VBG')]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# That of course tagged all the commas and apostrophes, so I'm just going to abort using the preprocessed text and \n",
    "# try it out with the original text.\n",
    "texts = test_df['txt'].tolist()\n",
    "tagged_texts = pos_tag_sents(map(word_tokenize, texts))\n",
    "tagged_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "      <th>txt_tokenized</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17195</th>\n",
       "      <td>17195</td>\n",
       "      <td>0</td>\n",
       "      <td>like bush did to obama with wars being waged t...</td>\n",
       "      <td>['like', 'bush', 'obama', 'war', 'wage', 'acco...</td>\n",
       "      <td>[(like, IN), (bush, NN), (did, VBD), (to, TO),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216649</th>\n",
       "      <td>216649</td>\n",
       "      <td>0</td>\n",
       "      <td>yikes if thats your question then im afraid yo...</td>\n",
       "      <td>['yike', 'that', 'question', 'im', 'afraid', '...</td>\n",
       "      <td>[(yikes, NNS), (if, IN), (thats, NNS), (your, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2812</th>\n",
       "      <td>2812</td>\n",
       "      <td>0</td>\n",
       "      <td>they do and these words mean a staff member of...</td>\n",
       "      <td>['word', 'mean', 'staff', 'member', 'campaign'...</td>\n",
       "      <td>[(they, PRP), (do, VBP), (and, CC), (these, DT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345482</th>\n",
       "      <td>345482</td>\n",
       "      <td>0</td>\n",
       "      <td>clearly you are not an understander of the sys...</td>\n",
       "      <td>['clearli', 'understand', 'system', 'that', 'e...</td>\n",
       "      <td>[(clearly, RB), (you, PRP), (are, VBP), (not, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947835</th>\n",
       "      <td>947835</td>\n",
       "      <td>0</td>\n",
       "      <td>good points but lets dispel with this fiction ...</td>\n",
       "      <td>['good', 'point', 'let', 'dispel', 'fiction', ...</td>\n",
       "      <td>[(good, JJ), (points, NNS), (but, CC), (lets, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  con                                                txt  \\\n",
       "17195        17195    0  like bush did to obama with wars being waged t...   \n",
       "216649      216649    0  yikes if thats your question then im afraid yo...   \n",
       "2812          2812    0  they do and these words mean a staff member of...   \n",
       "345482      345482    0  clearly you are not an understander of the sys...   \n",
       "947835      947835    0  good points but lets dispel with this fiction ...   \n",
       "\n",
       "                                            txt_tokenized  \\\n",
       "17195   ['like', 'bush', 'obama', 'war', 'wage', 'acco...   \n",
       "216649  ['yike', 'that', 'question', 'im', 'afraid', '...   \n",
       "2812    ['word', 'mean', 'staff', 'member', 'campaign'...   \n",
       "345482  ['clearli', 'understand', 'system', 'that', 'e...   \n",
       "947835  ['good', 'point', 'let', 'dispel', 'fiction', ...   \n",
       "\n",
       "                                                      POS  \n",
       "17195   [(like, IN), (bush, NN), (did, VBD), (to, TO),...  \n",
       "216649  [(yikes, NNS), (if, IN), (thats, NNS), (your, ...  \n",
       "2812    [(they, PRP), (do, VBP), (and, CC), (these, DT...  \n",
       "345482  [(clearly, RB), (you, PRP), (are, VBP), (not, ...  \n",
       "947835  [(good, JJ), (points, NNS), (but, CC), (lets, ...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally it worked (i know it's not on the preprocessed data, but by golly it finally worked, so I'm going to load \n",
    "# that info back into the dataframe. There must have been something with preprocessing, saving to a csv, then loading\n",
    "# the data that disrupted the flow. I did notice that when I loaded the preprocessed data from the csv it had apostrophes\n",
    "# that were not there before, but I couldn't keep running the preprocessing steps and using the data from that because it\n",
    "# was eating up my time, especially since I kept making my kernel die and having to restart a lot.\n",
    "test_df['POS'] = tagged_texts\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Step 2C: Term frequency-inverse document frequency (tfidf) vector***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "      <th>txt_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>well its great that he did something about tho...</td>\n",
       "      <td>['well', 'great', 'someth', 'belief', 'offic',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>you are right mr president</td>\n",
       "      <td>['right', 'mr', 'presid']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>you have given no input apart from saying i am...</td>\n",
       "      <td>['given', 'input', 'apart', 'say', 'wrong', 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>i get the frustration but the reason they want...</td>\n",
       "      <td>['get', 'frustrat', 'reason', 'want', 'way', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>i am far from an expert on tpp and i would ten...</td>\n",
       "      <td>['far', 'expert', 'tpp', 'would', 'tend', 'agr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  con                                                txt  \\\n",
       "0           0    0  well its great that he did something about tho...   \n",
       "1           1    0                         you are right mr president   \n",
       "2           2    0  you have given no input apart from saying i am...   \n",
       "3           3    0  i get the frustration but the reason they want...   \n",
       "4           4    0  i am far from an expert on tpp and i would ten...   \n",
       "\n",
       "                                       txt_tokenized  \n",
       "0  ['well', 'great', 'someth', 'belief', 'offic',...  \n",
       "1                          ['right', 'mr', 'presid']  \n",
       "2  ['given', 'input', 'apart', 'say', 'wrong', 'a...  \n",
       "3  ['get', 'frustrat', 'reason', 'want', 'way', '...  \n",
       "4  ['far', 'expert', 'tpp', 'would', 'tend', 'agr...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load up preprocessed data\n",
    "test = pd.read_csv('wk2_clean.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a sample of rows to work with\n",
    "tf = test.sample(frac = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the small sample that, I will run the Tfid Vectorizer to create a tf-idf feature matrix.\n",
    "v = TfidfVectorizer()\n",
    "x = v.fit_transform(tf['txt_tokenized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<190000x74557 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3086740 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the tf-idf feature matrix\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37796447, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.37796447,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.75592895, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.37796447, 0.        ],\n",
       "       [0.        , 0.47140452, 0.23570226, 0.23570226, 0.        ,\n",
       "        0.23570226, 0.23570226, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.23570226, 0.23570226, 0.        , 0.23570226,\n",
       "        0.        , 0.        , 0.        , 0.23570226, 0.23570226,\n",
       "        0.23570226, 0.23570226, 0.23570226, 0.23570226, 0.        ,\n",
       "        0.        , 0.        , 0.23570226, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.33333333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.33333333, 0.        ,\n",
       "        0.        , 0.        , 0.66666667, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.33333333, 0.33333333, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.33333333],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.37796447, 0.37796447, 0.        ,\n",
       "        0.37796447, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.37796447,\n",
       "        0.        , 0.        , 0.        , 0.37796447, 0.37796447,\n",
       "        0.37796447, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the smaller sample of 5, I am able to show the tf-idf feature matrix as a dense matrix\n",
    "x.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Follow Up Question***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the three techniques in problem (2) above, give an example where each would be useful.\n",
    "\n",
    "Word Count Vector: Gives us a numeric representation of text data that can then be used to categorize data or conduct clustering analysis on data. \n",
    "\n",
    "Part of Speech Tag Vector: Are useful in building parse trees and extracting relationships between words.\n",
    "\n",
    "Tf-idf Vector: provides a way to associate each words importance in a document and is used in information retrieval or summarization.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
